---
title: Importing and exploring new data
author: Luiza Andrade and Sushmita Samaddar
---

# Introduction

- Until now, we have been working with data that has already been processed
- This is because we wanted to get you familiar with the Stata syntax before we started digging into more difficult tasks
- Over the next few sessions, we will take you through the process that is needed to create the data that we were using before
- Then, we will show you how to create polished graphs and tables using this data

# Introduction

- The data set in `DataWork/Data/Final/process_data.dta` has been *imported*, *cleaned* and *constructed*
  - **Importing** means saving data that was received in a format external to Stata (such as Excel) into the Stata data set format (.dta)
  - **Cleaning** means changing the format of the data so it is easy to handle in Stata
  - **Constructing** means using the clean data to create indicators that we care about
- This session will take you through the very first step of this process, *data import*
- We will also discuss one very important aspect of data quality that should be inspected as soon as the data is imported: the presence of unique identifiers
- Finally, we will learn some new Stata tricks using logical operators to create subsets of the data and to remove variables from a data set
 
# Importing data from Excel	

- The data that was used to create the process-level data set we have been using until now was originally received in Excel format
- This raw data is stored in `DataWork/Data/Raw/process_raw.xlsx`
- However, for the reasons we have already discussed in the past two days, we have chosen not to work with this data in Excel
- So the first thing we need to do is to open this data into Stata
- We will do this using the command `import excel`

# Importing data from Excel	

**Exercise**: load the raw process data into Stata from Excel.

1. Launch Stata by opening the Stata project in `DataWork/Introduction to Stata.stpr`
2. Open a new do-file
3. Use `import excel` to load the data from `Data/Raw/process_raw.xlsx`
  - *Tip:* if you are not sure how to do this, start by looking at the helpfile
  
# Importing data from Excel	

**Exercise**: load the raw process data into Stata from Excel.

```{s}
import excel "Data/Raw/process_raw.xlsx", /// Path to the file to be loaded
	sheet("Sheet1") /// Name of the sheet where the data is
	firstrow /// Use first row in the data as variable names, not data points
	clear // Replace the data in memory with this data
```

# Saving data into Stata format

**Exercise**: load the raw process data into Stata from Excel.

```{s}
import excel "Data/Raw/process_raw.xlsx", /// Path to the file to be loaded
	sheet("Sheet1") /// Name of the sheet where the data is
	firstrow /// Use first row in the data as variable names, not data points
	clear // Replace the data in memory with this data
```


# Unique ID

The first thing you want to look for every single time you open a new data set for the first time is

1. **Unit of observation:** the object or unit that is being described in the data set
2. **Uniquely and fully identifying ID variable:** the column in the data set that can be used to tell one observation apart from the others
  - *Uniquely* identifying: cannot have duplicated values
  - *Fully* identifying: cannot be missing
  
# Unique ID

**Why** is it so important to have a unique identifier for our unit of observation?

# Unique ID

**Why** is it so important to have a unique identifier for our unit of observation?

- So we make sure that we are not giving one instace of the unit of observation more weight then others
- So we can use it to combine different data sets (more on this later in the course)

# Unique ID

- What is the *unit of observation* in the data set we have just loaded?
- What column identifies different instances of the unit of observation in the data set we have just loaded -- that is, what is its *ID variable*?

**Exercise:** browse the process data set and try to identify its unit of observation and ID variable.

# Unique ID

Commands for testing that a variable is uniquely and fully identifying
- `isid`
- `duplicates`

# `isid`

**`isid`** checks whether the specified variables uniquely identify the observations.

~~~
isid varlist [using filename] [, sort missok]
~~~

# `isid`

**Exercise:** use `isid` to test whether the variable `Process_Naziv` or `Process_Oznaka` uniquely identifies the observations in this data set.

~~~
isid Process_Naziv
isid Process_Oznaka
~~~

# `isid`

**Exercise:** use `isid` to test whether the variable `Nadmetanje_ID` uniquely identifies the observations in this data set.

```{s}
isid Nadmetanje_ID
```

# `isid`

**Exercise:** use `isid` to test whether the variable `Nadmetanje_ID` uniquely identifies the observations in this data set.

```{s}
isid Nadmetanje_ID
```

- Stata did not throw an error because `Nadmetanje_ID` is the ID variable

# `duplicates`

**`duplicates`** -- Report, tag, or drop duplicate observations

Report duplicates

~~~
duplicates report [varlist] [if] [in]
~~~

List one example for each group of duplicates

~~~
duplicates examples [varlist] [if] [in] [, options]
~~~

Tag duplicates

~~~
duplicates tag [varlist] [if] [in] , generate(newvar)
~~~

# `duplicates`

```{s}
duplicates report Process_Naziv
```

# `duplicates`

```{s}
duplicates tag Process_Naziv, gen(dup_name)
```

- `duplicates tag` did not print anything in the console because the information it creates is actually stored in a new variable called `dup_name`

# `duplicates`

`dup_name` will take the value of the number of duplicate observations for given value for the chosen variable

```{s}
summarize dup_name
```

# Logical operators and *if statements*

- We can use the *if statement* we learned earlier to investigate some of this cases
- As we have seen, *if statement* evaluate logic statements and return observations for which these statements are true
- Stata accepts the following logical operators:
  -	`a == b`: true if a is **equal** to b
  - `a != b`: true if a is **different** than to b
  - `a >  b`: true if a **greater than** b
  - `a >= b`: true if a **greater than or equal to** b
  - `a <  b`: true if a **less than** b
  - `a <= b`: true if a **less than or equal to** b
  - `a & b`: true if a **and** b are true
  - `a | b`: true if a **or** b are true
  - `!a`: logical **negation**; true if a is false
  
# Logical operators and *if statements*

Here is how we can use logical operators:

- View observations that have 1 duplicate entry for `Process_Naziv`

~~~
browse if dup_name == 1
~~~

- View observations that have *any* duplicates entries for `Process_Naziv`

~~~
browse if dup_name != 0
~~~

# Logical operators and *if statements*

**Exercise:** use logical operators to

- View observations that have *less than* 2 duplicates entries for `Process_Naziv`
- View observations that have 1 *or* 2 duplicates entries for `Process_Naziv`
- View observations that have 1 duplicate entries for `Process_Naziv` *and* whose process name is *equal* to "uredski materijal"

# Logical operators and *if statements*

~~~
browse if dup_name < 2
browse if dup_name == 2 | dup_name == 1
browse if dup_name == 1 & Process_Naziv == "uredski materijal"
~~~

# Logical operators and *if statements*

~~~
browse if dup_name < 2
browse if dup_name == 2 | dup_name == 1
browse if dup_name == 1 & Process_Naziv == "uredski materijal"
~~~

# Logical operators and *if statements*

If you start building complex statements, you can use parenthesis to organize them. Note that the way you use parenthesis will alter the result.

```{s}
count if dup_name == 1 & Process_Naziv == "uredski materijal" | dup_name == 2
count if (dup_name == 1 & Process_Naziv == "uredski materijal") | dup_name == 2
count if (dup_name == 1) & (Process_Naziv == "uredski materijal" | dup_name == 2)
```

# Drop observations

- `drop`: remove columns or rows from a dataset
  - Example
- `keep`: keep only columns or rows specified from a dataset
  - Example
- Exercise: drop if duplicate ID & ??

# Save data set

# Loading data from csv files

- Apart from Excel, another format that is commonly used to share data is comma-separated values, or csv
- The command that imports data from csv into Stata is very similar to the one that import Excel files

```{s}
import delimited "Data/Raw/process_raw.csv", /// Path to the file to be loaded
	encoding(windows-1250) /// How to read non-English characters
	clear /// Replace the data in memory
	bindquote(strict) // How to treat quotes found in the data
```
